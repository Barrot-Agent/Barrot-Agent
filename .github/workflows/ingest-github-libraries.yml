name: Dataset Ingestion - GitHub Libraries

on:
  schedule:
    # Run weekly on Sunday at 02:00 UTC
    - cron: '0 2 * * 0'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  ingest-github-libraries:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests jsonschema pyyaml

      - name: Ingest Programming Libraries
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          mkdir -p datasets/programming-libraries/github
          
          # Create library ingestion script
          cat > ingest_github_libs.py << 'EOFPYTHON'
          import os
          import json
          import requests
          from datetime import datetime, timezone
          
          # Target repositories for permutation libraries
          repositories = [
              "python/cpython",
              "more-itertools/more-itertools",
              "sympy/sympy",
              "Qiskit/qiskit",
              "quantumlib/Cirq"
          ]
          
          headers = {
              "Authorization": f"token {os.environ.get('GITHUB_TOKEN', '')}",
              "Accept": "application/vnd.github.v3+json"
          }
          
          ingested_libraries = []
          
          for repo in repositories:
              try:
                  url = f"https://api.github.com/repos/{repo}"
                  response = requests.get(url, headers=headers)
                  
                  if response.status_code == 200:
                      repo_data = response.json()
                      
                      library_info = {
                          "name": repo_data["name"],
                          "full_name": repo_data["full_name"],
                          "description": repo_data.get("description", ""),
                          "url": repo_data["html_url"],
                          "stars": repo_data["stargazers_count"],
                          "language": repo_data.get("language", "Unknown"),
                          "topics": repo_data.get("topics", []),
                          "last_updated": repo_data["updated_at"],
                          "ingestion_timestamp": datetime.now(timezone.utc).isoformat() + "Z"
                      }
                      
                      ingested_libraries.append(library_info)
                      print(f"Ingested: {repo}")
                  else:
                      print(f"Failed to fetch {repo}: {response.status_code}")
              
              except Exception as e:
                  print(f"Error processing {repo}: {e}")
          
          # Save library metadata
          os.makedirs("datasets/metadata", exist_ok=True)
          with open("datasets/metadata/github_libraries.json", "w") as f:
              json.dump({
                  "ingestion_timestamp": datetime.now(timezone.utc).isoformat() + "Z",
                  "source": "github",
                  "libraries": ingested_libraries,
                  "count": len(ingested_libraries)
              }, f, indent=2)
          
          print(f"Successfully ingested {len(ingested_libraries)} libraries")
          EOFPYTHON
          
          python ingest_github_libs.py

      - name: Search for Permutation Algorithms
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Create algorithm search script
          cat > search_algorithms.py << 'EOFPYTHON'
          import os
          import json
          import requests
          from datetime import datetime, timezone
          
          headers = {
              "Authorization": f"token {os.environ.get('GITHUB_TOKEN', '')}",
              "Accept": "application/vnd.github.v3+json"
          }
          
          search_queries = [
              "permutation algorithm language:python",
              "combinatorial optimization language:python",
              "recursive permutation language:python"
          ]
          
          algorithm_repos = []
          
          for query in search_queries:
              try:
                  url = f"https://api.github.com/search/repositories?q={query}&sort=stars&per_page=5"
                  response = requests.get(url, headers=headers)
                  
                  if response.status_code == 200:
                      results = response.json()
                      for item in results.get("items", []):
                          algorithm_repos.append({
                              "name": item["name"],
                              "full_name": item["full_name"],
                              "url": item["html_url"],
                              "description": item.get("description", ""),
                              "stars": item["stargazers_count"],
                              "language": item.get("language", ""),
                              "query": query
                          })
              except Exception as e:
                  print(f"Error searching '{query}': {e}")
          
          # Save algorithm search results
          with open("datasets/metadata/algorithm_search.json", "w") as f:
              json.dump({
                  "search_timestamp": datetime.now(timezone.utc).isoformat() + "Z",
                  "repositories": algorithm_repos,
                  "count": len(algorithm_repos)
              }, f, indent=2)
          
          print(f"Found {len(algorithm_repos)} algorithm repositories")
          EOFPYTHON
          
          python search_algorithms.py

      - name: Commit and Push
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add datasets/
          git commit -m "Ingest GitHub libraries - $(date -u +'%Y-%m-%d')" || echo "No changes to commit"
          git push
